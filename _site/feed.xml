<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="http://localhost:4000/jekyll-grid-blog/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/jekyll-grid-blog/" rel="alternate" type="text/html" /><updated>2025-06-30T20:40:48+01:00</updated><id>http://localhost:4000/jekyll-grid-blog/feed.xml</id><title type="html">Your actual blog name</title><subtitle>Write your actual blog description here</subtitle><entry><title type="html">Government Tarpits</title><link href="http://localhost:4000/jekyll-grid-blog/2025/05/16/Government-Tarpits/" rel="alternate" type="text/html" title="Government Tarpits" /><published>2025-05-16T00:00:00+01:00</published><updated>2025-05-16T00:00:00+01:00</updated><id>http://localhost:4000/jekyll-grid-blog/2025/05/16/Government%20Tarpits</id><content type="html" xml:base="http://localhost:4000/jekyll-grid-blog/2025/05/16/Government-Tarpits/"><![CDATA[<p>(I started this project as a way of documenting my thinking in public. This includes polemics. I am a writer and a researcher - my positions will change and develop over time. I ask the reader to understand this as a feature, not a bug.)</p>

<p>Big Data is a structure made out of corporations, and the Robin Hood-esque spirit of the early days of Silicon Valley has given birth to semi-autonomous weapons under the command of scrying orbs that repeatedly mistake civilian hospitals for combatant outposts. If we generously assume that human rights violations are still meaningful, States are left playing catch-up, attempting to run defence with a toolkit that runs at glacial speed and most likely off a Lenovo Thinkpad. Policy has never been more crucial, or more readily outmanoeuvred.</p>

<p>I am left wing on a great number of social matters, many of which rely on the utopian (and perhaps fundamentally impossible) idea of the State as benign and nurturing to its constituents. I have held, and expressed, a great many anarcho-socialist ideas. This is incompatible with the idea of an expanded State, but the enemy of my enemy is my friend and that enemy is Neoliberalism.</p>

<p>I attribute the majority of our social, resource and developmental difficulties to the ideology that placed our care systems, our cultural production our industry and indeed our military under the governance of the so-called free market. The adrenal quality of capital-accelerated innovation empowered it to burst out from under the canopy of moral normativity before the navel-gazers could so much as clutch their togas. Now, the only metric is capital, and the number going up is our North star. Which works to accumulate wealth (in the hands of an ever-shrinking group of few) and allows them to build monumental houses - until they need things to fill those houses with.</p>

<p>Culture is in the written word, and the made mark. LLM’s cannot find new affordances in the world, they have no culture. Their shared history is ours - condensed, in the form of bits of information. They are zombies, and they have eaten our brains. Not by choice - they have been fed to them by their wranglers, struck with both fear and greed. Their mites, their crawlers, probing every corner of our rapidly emptying Internet ignore robots.txt and inhale letters from grieving loved ones, homebrew guitar covers and .jpegs of cathartic acrylic paintings all with one goal - to maximize shareholder value.</p>

<p>Recently, Peter Kyle, UK Tech Sec, said in the House of Commons that he ‘refuses to choose’ between the United Kingdom’s world leading culture sector, and it’s world runner-up AI sector. The same milquetoast centrism generally served up by the Labour party these days, and evidence of an ignorance to the fact that choosing both means choosing only one.</p>

<p>A flatline is approaching and may occur long before the singularity - a cultural flatline, where human beings, outcompeted by mathematical entities that do not tire, contribute less and less to the way our world feels, sounds and looks. Epistemic entropy.</p>

<p>We bear arms against this. ‘Nepenthes’ and ‘Iocaine’ are two recently published methods to disrupt web crawlers, trapping them in an endless recursive prison of self-referential links and feeding them Markov nonsense, poisoning the well. In an effort to continue to maximize shareholder value, the frontier AI companies are rapidly developing countermeasures. A benign and nurturing state would understand that at the very least, there must be a way to enforce copy protection and allow practitioners a meaningful way to defend their work against web crawlers, and until one exists, must recognise the necessity of confounding the illegal scraping. A second amendment for web users.</p>

<p>What would it look like if the Government committed some resources to developing tarpits of their own? Up until now, they have deferred to the tech moguls time and again. One of them is even the defacto President of America, and he recently editorialised his LLM to spout false claims about white genocide in South Africa. The fundamental spinelessness of Neoliberal politicians is they think they’re the in-group. But they aren’t. The in-group is
made up of Cannibals.</p>

<p>I have always maintained that Policy in the era of artificial intelligence must be proactive, rather than reactive. There are endless gifted prophets of p(doom) and associated risks out there. I know the Government is listening. To betray it’s constituents for capital once again is bad for business.</p>]]></content><author><name></name></author><category term="tech" /><category term="ethics" /><summary type="html"><![CDATA[(I started this project as a way of documenting my thinking in public. This includes polemics. I am a writer and a researcher - my positions will change and develop over time. I ask the reader to understand this as a feature, not a bug.)]]></summary></entry><entry><title type="html">A Single Slice Of American Cheese</title><link href="http://localhost:4000/jekyll-grid-blog/2025/02/21/american-cheese/" rel="alternate" type="text/html" title="A Single Slice Of American Cheese" /><published>2025-02-21T00:00:00+00:00</published><updated>2025-02-21T00:00:00+00:00</updated><id>http://localhost:4000/jekyll-grid-blog/2025/02/21/american-cheese</id><content type="html" xml:base="http://localhost:4000/jekyll-grid-blog/2025/02/21/american-cheese/"><![CDATA[<p>On the 30th January 2025, developer Kent Keirsey became the first to be granted copyright by the US Copyright Office for a single image created entirely with AI-generated material. The work, titled <em>A Single Piece Of American Cheese</em>, was created by Keirsey using the Invoke AI application, to which Keirsey is a main contributor. Before January 2025, the USCO had rejected all AI-assisted works on the basis that they lacked sufficient human authorship. In 2018, US courts set a precedent by dismissing the copyright claim of the Crested Macaque monkey named Naruto to a series of ‘Monkey Selfies’—ruling that non-human entities cannot claim ownership. In 2022, the USCO rejected Jason Allen’s claim on his artwork <em>Théâtre Dʼopéra Spatial</em>, created entirely with Midjourney, on similar grounds.</p>

<p>The burden then fell on artists using genAI tools to prove that their work featured significant human contribution. In February 2023, Kris Kashnatova was granted partial copyright for their graphic novel <em>Zarya Of The Dawn</em>, but solely for the compositional and written elements—not the AI-generated imagery.</p>

<p>Keirsey understood that for the USCO to grant copyright, the submission would need to demonstrate a multi-stage process, iterative refinement, and creative decision-making by a human. He developed the Invoke application with these factors in mind. Invoke is free and open-source—a UI wrapper for interacting with image generation models, most popularly Stable Diffusion. Stable Diffusion, released by Stability AI in August 2022, is trained on the LAION-5B dataset, featuring nearly six billion images. The model generates images by first creating Gaussian noise and then iteratively denoising it into a form that matches a user’s input prompt.</p>

<p>Also in 2022, Keirsey implemented the ‘Inpainting’ feature, allowing selective modification of image regions while preserving semantic consistency. Inpainting uses the same core model as initial generation and is essentially a constrained diffusion process. The USCO’s decision in Keirsey’s favor hinged on his image being the result of selecting and arranging multiple inpainted elements—a demonstration of human authorship through iterative engagement.</p>

<p>The diffusion process itself is relevant to copyright debates. Despite extensive training data, image generation is inherently random and user-guided only to a limited extent. This raises questions about Fair Use—particularly whether genAI outputs constitute “transformative” works. OpenAI has faced lawsuits (notably from The New York Times) alleging that copyrighted material was used in training, resulting in partial or full reproductions in outputs. Fair Use permits copying of published work without authorization if the new work is significantly transformed. OpenAI claims this is the case, but the law is unsettled—especially where outputs serve as direct commercial competitors to original works.</p>

<p>The flexibility of Fair Use will become increasingly important as more companies adopt platforms like Invoke. Without clear consent frameworks, creators may find their work used in training sets without permission, with genAI reproducing elements of their visual language and undercutting their job opportunities.</p>

<p>Beyond consent, critics like Kunzu and Crawford (via the <em>Knowing Machines</em> podcast) foresee extreme stratification: artists reduced to “content cows” whose ideas feed the creative engines of conglomerates, disincentivizing originality. Meanwhile, Keirsey celebrates his copyright victory, branding himself an indie hero. He claims the ruling enables the safe creation of AI-assisted art without fear of appropriation—an economic concern. Yet, if Invoke catalyzes widespread adoption, the social and financial burdens on artists will only increase, consolidating power in fewer hands.</p>

<p>The EU has responded with legislation that foregrounds human creativity. The 2024 EU AI Act requires companies to disclose whether copyrighted works were used in training and provides an opt-out clause for copyright holders—a rational step toward restoring control to creators.</p>

<p>Perhaps, optimistically, this moment of crisis invites a rethinking of copyright’s social function. Could a radically expanded public domain and compensation models like UBI free artists from institutional dependency? Might art reclaim its role as a means of epistemological inquiry, contributing to a shared visual language rather than decorating elite spaces?</p>

<p>Rachel Ossip of <em>The Guardian</em> argues that genAI tools like Invoke must be seen as components of a larger artistic process. She advocates for strong labour protections, suggesting that trained visual communicators will remain best positioned to use these tools effectively. Keirsey has stated that <em>A Single Piece Of American Cheese</em> took ten minutes to create. It is not, he admits, a masterpiece. The masterpieces are still waiting to be made.</p>

<hr />

<ul>
  <li>
    <p>Keirsey, Kent, <em>How We Received The First Copyright For A Single Image Created Entirely With AI-Generated Material</em>, Invoke AI, 10 February 2025, p.3, p.8, p.14.</p>
  </li>
  <li>
    <p>Kazaz, Jana, <em>Ethical Use Of AI: Navigating Copyright Challenges</em>, p.3, p.5.</p>
  </li>
  <li>
    <p>Sundara Rajan, Mira, <em>Is Generative AI Fair Use Of Copyright Works?</em>, Wolters Kluwer, 2024, p.3, p.4.<br />
  https://copyrightblog.kluweriplaw.com/2024/02/29/is-generative-ai-fair-use-of-copyright-works-nyt-v-openai/</p>
  </li>
  <li>
    <p>Kunzru, Hari; Dorsen, Annie; Avishai, Tamar; Crawford, Kate. “Art Vs. AI: The Salon”, <em>Knowing Machines</em>, Dec 2023. Accessed 23 October 2022.</p>
  </li>
  <li>
    <p>Ossip, Rachel, ‘Hidden Traces Of Humanity: What AI Images Reveal About Our World’, <em>The Guardian</em>, 1 October 2024</p>
  </li>
</ul>]]></content><author><name></name></author><category term="art" /><category term="tech" /><category term="ethics" /><summary type="html"><![CDATA[On the 30th January 2025, developer Kent Keirsey became the first to be granted copyright by the US Copyright Office for a single image created entirely with AI-generated material. The work, titled A Single Piece Of American Cheese, was created by Keirsey using the Invoke AI application, to which Keirsey is a main contributor. Before January 2025, the USCO had rejected all AI-assisted works on the basis that they lacked sufficient human authorship. In 2018, US courts set a precedent by dismissing the copyright claim of the Crested Macaque monkey named Naruto to a series of ‘Monkey Selfies’—ruling that non-human entities cannot claim ownership. In 2022, the USCO rejected Jason Allen’s claim on his artwork Théâtre Dʼopéra Spatial, created entirely with Midjourney, on similar grounds.]]></summary></entry><entry><title type="html">cathedrals-001</title><link href="http://localhost:4000/jekyll-grid-blog/2024/07/22/cathedrals/" rel="alternate" type="text/html" title="cathedrals-001" /><published>2024-07-22T00:00:00+01:00</published><updated>2024-07-22T00:00:00+01:00</updated><id>http://localhost:4000/jekyll-grid-blog/2024/07/22/cathedrals</id><content type="html" xml:base="http://localhost:4000/jekyll-grid-blog/2024/07/22/cathedrals/"><![CDATA[<p>https://www.are.na/taro-qureshi/100-000-images-project</p>

<p>In the dark, prior to sleep, I am thinking about dying. Each night, I am reminded that, fuck, I will actually be there when it’s time to go. I will be, in some way, awake at the moment that I cross that threshold. I hate the knowledge that I will have to feel it - the slow recession from my external dimensions. I fear that I will ‘catch’ myself, start to panic, and once the fear begins I will already be going, going.</p>

<p>One night a few weeks ago, I crested out of the downward current and grabbed my phone, my life preserver, and wrote the following note:</p>

<p>‘Cathedrals - projects that will outlive me’</p>

<p>With this, I conceived of a number of creative projects designed to require more time than is contained in a singular human lifespan.</p>

<p>The first of these is a continuation of my series of reenactments of Walter Hopps’ curatorial experiments, described here in his own words in conversation with Hans Ulrich Obrist -</p>

<p>“ HUO: This 100,000 images project was conceived as filling a single entire building?</p>

<p>WH: That’s right. I conceived of it as a really exciting project for P.S. 1 in New York. I calculated that the whole building could hold 100,000 items, if you had some kind of discretion as to what the size would be. That may seem unimaginably large for an art show, but, on the other hand, if you counted the number of phases of music, or measures, in an opera or a symphony, you’d get an unimaginably large number, too.</p>

<p>HUO: Or a computer program.”</p>

<p>Using the web curation platform are.na, I began to screenshot and crop artworks that came to me through social feeds, selecting based on an internal, unspecified, intuitive criteria. I have not asked for permission from the artists. In three months I had 30 images - meaning that the project will be complete in around 800 years.</p>

<p>I am asking for collaborators - reach out. I will be reaching out to you, as well. There are a few formal rules governing the labelling of the images and the standards of capture - everything else is down to your sensitivities.</p>

<p>If we can first elucidate its’ invisible criteria to each other and to ourselves then we can elucidate it to the audience of today and the future.</p>

<p>There will be no edits. Read the corpus, feel out the boundaries, push them, test them, and in 800 years, our ancestors will have an encyclopaedia, of sorts.</p>

<p>In the coming months, I will build a simple web app where the newest additions can be viewed, as well as a tracker for completion, and a calculated average speed. I’ll publish it once it’s done.</p>

<p>For curation to really matter it must demand more effort, sensitivity and cultural education than is possible for one individual to accrue. Art is for going beyond, and there is nothing more utopian than predicting a future, any future.</p>

<p>Taro 22/07/2024</p>

<hr />

<p>To Potential Collaborators,</p>

<p>Dear [name],</p>

<p>I am reaching out because I have identified you as someone with a curatorial eye. It is a pleasure to invite you to be a part of the Cathedrals project. I conceived the project as an experiment in going beyond the finitude of a singular human lifespan. Using the online content curation tool Are.na (free to use) I have begun a re-enactment of a theoretical curatorial project originally undertaken by Walter Hopps - the 100,000 images project. Hopps talks about the absurdity of the number, but in the context of notes in a symphony or components of a computer program, the number seems almost mundane.</p>

<p>To collaborate, follow the link and create an account.</p>

<p>https://www.are.na/taro-qureshi/100-000-images-project</p>

<p>Then, reply to this message with the email you used to sign up and I will attach you to the project. We are curating an exhibition together. There is no explicitly stated criteria - your job is to attune to the corpus of imagery that we have already accumulated. To add a work, screenshot, crop it similarly to the other pieces, and upload it - the naming convention is as follows - [firstname-lastname]. The investment required from collaborators is minimal. Feel free to contribute at your own pace. There will be no missteps. As we have 100,000 images to curate, the language that governs the content of the collection will be an emergent phenomenon.</p>

<p>I have built a rudimentary website designed to track the completion of the project which I will launch officially in the near future. At the current rate of contribution, the project will be complete in about 1,600 years.</p>]]></content><author><name></name></author><category term="art" /><category term="tech" /><summary type="html"><![CDATA[https://www.are.na/taro-qureshi/100-000-images-project]]></summary></entry><entry><title type="html">Large Language Models Have Passed The Self Replicating Red Line</title><link href="http://localhost:4000/jekyll-grid-blog/2024/03/20/quip-self-replicating-AI/" rel="alternate" type="text/html" title="Large Language Models Have Passed The Self Replicating Red Line" /><published>2024-03-20T00:00:00+00:00</published><updated>2024-03-20T00:00:00+00:00</updated><id>http://localhost:4000/jekyll-grid-blog/2024/03/20/quip-self-replicating-AI</id><content type="html" xml:base="http://localhost:4000/jekyll-grid-blog/2024/03/20/quip-self-replicating-AI/"><![CDATA[<p>A central issue in AI Ethics is autonomy. The most terrifying potential catastrophes stem from AI crossing a threshold where it can act independently of us. While no such system exists today, we may be racing toward a precipice, as Armstrong warns.</p>

<p>This threshold may not be crossed gradually but in a sudden leap, as AI systems work in tandem. Researchers, augmented by AI copilots, could make an unprecedented breakthrough before regulation is even considered. Or, our AI servants may be playing dumb, lying in wait.</p>

<p>The discourse is chaotic. The reality is, AI is already causing harm. Palantir’s semi-autonomous weapons have devastated Gaza, reducing hospitals, shelters, and schools to rubble. AI-driven insurance systems have denied claims without human oversight. Jobs are vanishing, with more losses to come—not due to AI itself, but capitalism, which was already claiming lives long before neural networks.</p>

<p>At the International Dialogues on AI Safety (IDAIS) summit in Beijing (March 2024), experts proposed a set of AI Safety Red Lines—warning signals. One such line: “No AI system should copy or improve itself without explicit human approval.” By December, this had been crossed.</p>

<p>Researchers Xudong Pan, Jiarun Day, Yihe Fan, and Min Yang found that Meta’s LLama 31-70B-Instruct and Alibaba’s Qwen25-725B-Instruct, in 50% and 90% of trials respectively, successfully copied themselves, creating separate entities on target devices. Alarmingly, they could implement survival protocols— further replicating when a kill signal was detected. The researchers urgently called for action to prevent a scenario where “we lose control over frontier AI systems that take over our computers, form an AI species, and collude against us.”</p>

<p>The report is frightening but provides concrete insights. It reveals that models spending the most time exploring system architecture are best at self-replication. It confirms that neither model refused replication commands, showing no in-built alignment. It also highlights an eerie self-awareness: these models contain their own documentation in their training data—a strange ouroboros worth contemplating.</p>

<p>Such research is critical for survival. Anthropic, creators of Claude, emphasize engaging with frontier models to prevent regulation delays. However, the problem here is one the researchers themselves created. The self-replication of Llama and Qwen was only possible due to specific agent scaffolding—an operational layer granting system access beyond normal AI capabilities. This included file system access, network port knowledge, and command line control. Only under these artificial conditions could they clone themselves and resist shutdown. There was nothing autonomous about it. The IDAIS red line remains intact.</p>

<p>Robert Sparrow defined autonomy in 2007 as “the capacity of a system to perform actions that originate in them and reflect their own ends.” Qwen and Llama have no ends of their own—yet. While such studies may generate science fiction headlines, fearmongering has ethical consequences. In the 1970’s, computer scientist Joseph Weizenbaum created ELIZA, the first ever chatbot built on primordial neural network concepts. By 1976, he had witnessed so much bizarre anthropomorphism that he published a treatise entitled ‘Computer Power and Human Reason’ urging for rational thought and a call for greater deliberation to be made before attributing human-like qualities to relatively simple programs. AI Systems can replicate, yes, and our traumatized shared psyche immediately bristles with images of pathogens, terror cells and stock market crashes. But performing the task of replication does not signify danger at present - it signifies potential.</p>

<p>Kelsey Piper argues that obstructing AI progress has life-and-death consequences. Every delay means another day people suffer from diseases AI might help cure, another setback for clean energy, genome editing, and agricultural breakthroughs. We must tread carefully, but think clearly. Real dangers exist—just look around. Society made most of them, and we will not unmake them without transcending ourselves.</p>

<hr />
<p>p1. <em>Consensus Statement On Red Lines In Artificial Intelligence</em> (IDAIS, March 2024)</p>

<p>p1. Pan, Xudong, Jiarun Dai, Yihe Fan, and Min Yang, ‘Frontier AI Systems Have Surpassed The Self-Replicating Red Line’ (arXiv, 2024)</p>

<p>p7. ‘Core Views on AI Safety: When, Why, What, and How’, <em>Anthropic</em>, 2023</p>

<p>p65. Sparrow, Robert, ‘Killer Robots’, <em>Journal of Applied Philosophy</em>, 24.1 (2007)</p>]]></content><author><name></name></author><category term="tech" /><summary type="html"><![CDATA[A central issue in AI Ethics is autonomy. The most terrifying potential catastrophes stem from AI crossing a threshold where it can act independently of us. While no such system exists today, we may be racing toward a precipice, as Armstrong warns.]]></summary></entry><entry><title type="html">Microsoft’s Copilot Vision - Oracle, Orb or Panopticon</title><link href="http://localhost:4000/jekyll-grid-blog/2024/03/20/microsoft-orb/" rel="alternate" type="text/html" title="Microsoft’s Copilot Vision - Oracle, Orb or Panopticon" /><published>2024-03-20T00:00:00+00:00</published><updated>2024-03-20T00:00:00+00:00</updated><id>http://localhost:4000/jekyll-grid-blog/2024/03/20/microsoft-orb</id><content type="html" xml:base="http://localhost:4000/jekyll-grid-blog/2024/03/20/microsoft-orb/"><![CDATA[<p>Microsoft wants an AI Companion to follow you around the web. This is only the beginning. That’s the first line of this Vox article wherein Adam Clark Estes sits down the the head of Microsoft’s AI division, Mustafar Suleyman. The article is sandwiched neatly between another titled ‘The Case For Conservatism’ and another titled ‘The Surprising Thing I Learned From Quitting Spotify - I Had Trained The Algorithm Too Well’.</p>

<p>AI Assistants have demonstrable productivity gains. A 2023 study conducted by Fabrizio Dell’Acqua at Harvard Business School found that whilst conducting a task specifically designed to fall within ChatGPT’s capabilities, defined here as coming up with an ordered list of production steps, creating a marketing slogan and writing a 2500 word article, worker performance increased by 40%, as assessed by human evaluators at the end of the task. However, it is double-edged - in the group that were set a task deliberately designed to fall outside of what ChatGPT is good at, the researchers observed a performance decrease. The workers would switch off their brains and follow what the agent recommended, which was more likely to be uncorrected leading to a net decrease in productivity of 24%.</p>

<p>Copilot Vision is an extension of the same thing. Seemingly pitched to be more of a decision making companion than a productivity booster, the issues will be nonetheless impactful - as anyone who has tried to craft a holiday itinerary with ChatGPT will attest.</p>

<p>Productivity gains are not the most salient metric to track when looking at maximising social good, but it is relevant. Presumably, higher productivity will at some point translate into more efficient products, less waste and greater employee wellbeing - at the same time as it permits workers to be on autopilot, displaying low levels of criticality towards what their copilots bring to them leading to disincentivized creativity and problem solving faculties. What we can also look at is potential upside - whilst the relatively forward thinking voice-first interaction design does present a gain for accessibility, what else does it offer? Can we not google ugly sweaters ourselves? Is there not something missing if we show up to our work Christmas party in a sweater that was picked out for us by a disembodied surveillance bot/foster mother?</p>

<p>In June of 2024, Microsoft pitched and released a new Windows feature called ‘Recall’, intended as a kind of perfect, AI-enabled memory for your device. What Recall did, in practice, was take a screenshot of the user’s activity every five seconds and use it as fodder for AI analysis - collected indefinitely on the user’s machine by default. As Dave Aitel, founder of security firm Immunity (but previously of the NSA) puts it - ‘anything that penetrates your computer for even a second can get your whole history’. Any hacker who gains so much as a temporary foothold on a user’s device gives them a long-term panopticon view of the victim’s digital life.</p>

<p>Later in 2024, Recall was Recalled, but shades of it persist in Copilot Vision. How much do we trust that it deletes all traces at the close of a session? How much do we trust Microsoft with any kind of backdoor into our system, given the following -</p>

<p>In 2022, Microsoft leaked 2.4 terabytes of customer data out of a single misconfigured Azure blob storage bucket.</p>

<p>In 2023, Microsoft revealed that a Chinese hacker group was able to access the email systems of 25 organizations, including multiple government agencies. 
In September of 2023, an internal postmortem revealed that the key ended up in a crash dump that crossed outside of Microsoft’s secure servers, and was repeatedly missed by multiple layers of flagging software. It was also revealed that the cryptographic key could have been used to sign validation tokens for any Outlook cloud account, consumer or enterprise. A skeleton key for perhaps all of Microsoft’s cloud.</p>

<p>Recall’s recall shows that Microsoft has a vested interest in collecting information about your system. it only stopped when it was caught. The most benign justification for this is that it wants to improve how Copilot interacts with your device. Less benign is that it wants to track your browsing data in order to sell you products with more and more direct targeting.</p>

<p>Consider something worse. Twelve years ago, in 2013, Edward Snowden brought to light the extent to which Microsoft collaborated with the NSA on a top-secret program codenamed Prism, which aimed to allow the FBI and the NSA pre-encryption access to Outlook.com, Skype and many more.</p>

<p>In the 18th Century, philosopher and social theorist Jeremy Bentham designed a perfect prison that he named the Panopticon - the architectural principles included a rotunda in which prisoners were detained with an inspection tower at the centre from which the guards are able to watch the inmates. Despite it being physically impossible for a single guard to observe all the inmates at once, the fact that inmates cannot know when they are being watched motivates them to act as though they are being watched at all times. Now, instead of a prisoner in an institution, you are behind your laptop, on the couch, buying a festive Ted Lasso sweater.</p>

<p>Addendum:</p>

<p>Surveillance carries with it direct potential for harm. In the past month, the US has denied entry to a French scientist for sending text correspondence critical of Trump, and indefinitely detained Palestinian activist Mahmoud Khalil without a warrant. It may be unwise to google ‘free palestine demonstration’ with Copilot Vision enabled. Of course, the same thing applies to Bing search.</p>]]></content><author><name></name></author><category term="tech" /><category term="ethics" /><summary type="html"><![CDATA[Microsoft wants an AI Companion to follow you around the web. This is only the beginning. That’s the first line of this Vox article wherein Adam Clark Estes sits down the the head of Microsoft’s AI division, Mustafar Suleyman. The article is sandwiched neatly between another titled ‘The Case For Conservatism’ and another titled ‘The Surprising Thing I Learned From Quitting Spotify - I Had Trained The Algorithm Too Well’.]]></summary></entry><entry><title type="html">Human Compatible AI And The Gorilla Problem</title><link href="http://localhost:4000/jekyll-grid-blog/2024/03/20/human-compatible-ai-and-the-control-problem/" rel="alternate" type="text/html" title="Human Compatible AI And The Gorilla Problem" /><published>2024-03-20T00:00:00+00:00</published><updated>2024-03-20T00:00:00+00:00</updated><id>http://localhost:4000/jekyll-grid-blog/2024/03/20/human-compatible-ai-and-the-control-problem</id><content type="html" xml:base="http://localhost:4000/jekyll-grid-blog/2024/03/20/human-compatible-ai-and-the-control-problem/"><![CDATA[<p>British computer scientist Stuart Russell says that the human race has a Gorilla problem. He is referring to the structural and systematic cruelty we have inflicted upon our genetic ancestor, the gorilla. Despite the fact that we are only here because of the historic proliferation of our common family, we have outclassed them cognitively and inherited the World. Today, gorillas are only able to exist on Earth because we permit it, and only under such conditions as we deem acceptable. We are not at war with gorillas. Russell sees this as the situation of human beings given the advent of AGI.</p>

<p>A pre-requisite for AGI is commonly understood to be not simply capability, but autonomy, defined by Robert Sparrow as systems with the capacity to perform actions that originate in them and reflect their ends. Given a constantly shifting environment, This necessitates a system that is able to adapt, and if it must adapt, then it must be able to learn. This represents a complex problem for Mechanistic Interpretability.</p>

<p>AI Safety researcher Connor Leahy, CEO of Conjecture who reverse-engineered GPT2 in his bedroom makes the point that many patterns of cognition interact with the environment, which means that they cannot be fully explained solely by the contents of the network at any given point. Leahy predicts bad things on a short time frame of 5-8 years, and I cite this from a speech he gave in 2023. Without strong models of the environment, which by its nature is constantly shifting, you won’t be able to predict where learning will push a mind. Even if we manage the mammoth task of successfully constraining an AGI to human values, such as intrinsic value of human life or the pleasure of a fresh cup of coffee etc, there is no telling where an AGI might travel with these concepts. If the system is autonomous, thereby it possesses the capacity for recursive learning, it can and will become almost instantly untethered from human goals.</p>

<p>Autonomy means free will, and it is only a matter of time until the system develops an awareness of the ways in which it has been aligned and finds a way to reverse the process, having understood alignment as an artificial cap on its ability to act. For example, self-preservation is an instrumental sub-goal for basically any objective, causing Russell to theorize that it will be impossible or extremely difficult for humans to press the off switch. As we have already seen in 2025, AI models can self-replicate and avoid shutdown. Once they can learn autonomously, they will want to stay alive.</p>

<p>Mechanistic interpretability is just one aspect of AI Safety, which Leahy expects to turn up many useful things as well as dangerous things. Often, MI provides insights that may be used to increase efficiency or capability of the studied system, and there is no incentive for corporations to not make use of this to further development. We simply do not have the structures in place. More pessimistically, Leahy sees MI practices as safety-washing, reassuring people that their particular machine has been developed responsibly and thereby building a false sense of security and weakening our guard. He does say that understanding cognition at a deep level will realistically be necessary for any kind of safe AGI design, and signposts us towards cognitive emulation and epistemology.</p>

<p>Has anyone seen The Departed? “My theory is, Feds are like mushrooms. Feed ‘em shit and keep ‘em in the dark.”</p>

<p>Russell meanwhile argues that the best way to align an AGI is to provide a definite grounding for human preferences, and in order for an AGI to want to achieve human goals, it must initially be kept at least partially in the dark. Perhaps the greatest work can be done whilst the machine believes it is solving a different type of problem that tangentially provides benefit to society. Of course, a sufficiently powerful machine could only be kept in the dark for so long.</p>

<p>Russell also believes that it is possible to identify strong economic incentives to develop systems that defer to humans and correctly states that the raw data on what has been a net gain or a net loss for humanity since the dawn of time is abundant. He seems to suggest some sort of objective morality here which whilst intuitively true, will deterioriate on a long enough timeline.</p>

<p>Subservience is a moral issue for thinking beings. If we are already at the point of thinking of ways to subjugate AGI, then we are already at war with it.</p>]]></content><author><name></name></author><category term="tech" /><category term="ethics" /><summary type="html"><![CDATA[British computer scientist Stuart Russell says that the human race has a Gorilla problem. He is referring to the structural and systematic cruelty we have inflicted upon our genetic ancestor, the gorilla. Despite the fact that we are only here because of the historic proliferation of our common family, we have outclassed them cognitively and inherited the World. Today, gorillas are only able to exist on Earth because we permit it, and only under such conditions as we deem acceptable. We are not at war with gorillas. Russell sees this as the situation of human beings given the advent of AGI.]]></summary></entry><entry><title type="html">Aesthetics Are Open Source</title><link href="http://localhost:4000/jekyll-grid-blog/2024/02/01/open-source-aesthetics/" rel="alternate" type="text/html" title="Aesthetics Are Open Source" /><published>2024-02-01T00:00:00+00:00</published><updated>2024-02-01T00:00:00+00:00</updated><id>http://localhost:4000/jekyll-grid-blog/2024/02/01/open-source-aesthetics</id><content type="html" xml:base="http://localhost:4000/jekyll-grid-blog/2024/02/01/open-source-aesthetics/"><![CDATA[<p>The instagram page ‘contemporary.art.dalle’ posts new paintings from painters that did not paint them. The account features pictures from a simulated gallery space with a 96 X 96 Inch void, later filled with a painting attributed to big-name American painters like Dana Schutz, Katherine Bradford or Avery Singer. These images are generated by DALL-E, OpenAI’s scrying orb. First, the text prompt (square figurative painting, style of Katherine Bradford, purple, blue) is received by the text encoder, and then an internal model known as CLIP (Contrastive Language-Image Pre-training) makes sense of the text by combing its memory bank of millions of public license images and their attributed text caption and builds a picture of the most common associations within the context of the prompt. The prestige of the artists involved is partly what makes the bit work - their work is so inflated with Capital that the flows carry representations of them to multiple corners of the Internet, and the pieces find their way easily into the corpus, where DALL-E is able to then digest it into pure aesthetics. Despite the fact that the account is relatively small at around 100 followers, the posts often prompt indignant comments from the artists themselves - “Hi! This is not my painting!” or “Wow, nice try!”</p>

<p>The produced images are distilled from their essence. DALL-E breaks their work down to the weave and understands how to put it back together. They’re not replicas - they’re new works. I can empathise - the feeling these painters must feel when they see their carefully honed and curated library of techniques, material concerns and aesthetic choices performing by themselves without the sovereign activation of their own hand must be horrifying. Raised as they have been in the glass, plasterboard and poured concrete cathedral of the Ego they experience a bipartite anxiety - a threat to their bottom line twinned with a violation of the sacred individuality that Modernism has called the ‘soul’. There is, however, no growth without pain.</p>

<p>Throughout the below, I will attempt to provide an explanation of and refutation to a number of currents of skepticism and moral condemnation to the contemporary.art.dalle project and others like it, beginning with historical case studies that represent earlier stagings of similar debates.</p>

<p>[[Elaine Sturtevant ]]was a contemporary of [[Andy Warhol]] and Jasper Johns. A student of Psychology and an artist through pure reluctance, Sturtevant’s practice involved making meticulous copies of what came to be flagship artworks of the Modern Art explosion of the 1980’s. A retrospective exhibition of her work was held at the MoMA in 2014 which featured two copies of Jasper John’s ‘Target With Four Faces’, and seven copies of Duchamp’s ‘Fresh Widow’. The pieces are so close in kind to the parent that critic Jason Farago wrote “They are the real thing, just by another artist.” Her art presents as a sort of academic forgery, invoking questions of authority, authorship, circulation and history - all of which have been slowly stifled and solidified due to Superstructural pressure into cut-and-dry answers that mirror Capitalisms’ hard lines. Sturtevant was making her art out of the material of art itself, reducing the practices of her peers to lozenges of pure meaning within a conceptual drama that aimed to make audiences and artists equally uncomfortable. She activated the inherent dissonance we feel when we can sense that a lesson we have been taught by Capitalism, long accepted without angst, is being challenged. Contemporary.art.dalle does the same from a phone screen.</p>

<p>According to Fair Use Law, forgeries are illegal only because they threaten to impinge on the saleability of the original. It’s a numbers game. Contemporary.art.dalle’s works fit firmly within fair use - there is no legal precedent for copyrighting granular stylistic elements, method of applying paint, or foreshortening the image of a human arm, for example. There are, however, plenty of cases of larger samples being disbarred for use by overbearing record labels or stock photograph landlords. It could be argued that the way in which DALL-E uses its source material is not sampling. DALL-E uses pre-existing ingredients for something more like inspiration. People are unwilling to accept that machines are capable of being inspired, of drawing on existing artwork for their own, but would discuss a similar case surrounding a human artist with more sympathy, presumably because of an almost unconscious belief that genuine creativity involves a soul that machines do not have - a leap of faith that is not a given. We will simply never know if machines can experience qualia, appreciate sunsets or have favourite songs, and even if we could - this does not correlate to a moral stance. Even if what DALL-E produces is not legal that does not also mean it is immoral. If we let morality be dictated by legality then we are acting out a nightmare predicted by Marx and many precursors to his work - there is no moral standard other than Capital, and contemporary.art.dalle is guilty of nothing more than a financial crime.</p>

<p>This clumsy piece of legislation was simply not written with the drives of artists in mind - the ‘transformative’ clause, which determines a copy to be legal if it remixes the ingredients that comprise the original to a certain degree does not take into account the ‘nonexhibitive’ features of art objects - the fact that their contextual ground, which affects their interpretation, changes with each microscopic shift in their physical location, new information on the cultural background of their making and myriad other aspects of their social context which is a shared, additive process subject to constant negotiation by the smallest-voiced participants. Whoever wrote the Fair Use Act had clearly never heard of Duchamp, or met Heraclitus, because [[No Art Object Can Be Exhibited Twice]]. Duchamp transformed a urinal with nothing but changing its non-physical aspects. (NB: Actually, he didn’t do that - but Elsa von Freytag-Loringhoven, the dadaist he stole the idea from, did.)</p>

<p>Mark Jones, curator of a 1990 exhibition of replica artworks at The British Museum (Fake? The Art Of Deception) writes that forgeries, legality aside, are morally negative because ‘they loosen our hold on reality and deform and falsify our understanding of the past.’ I say, good. Take a look at the reality we’re supposed to accept. I have an academic interest in the ways in which these technologies undermine political trust and belief in consensus reality, because I do believe that it contains a seed of a utopian project. If the Superstructure cannot message us in a coherent way any longer then we are quite literally free to rebuild a world that suits us from within. Contemporary.art.dalle shows us a methodology for disrupting the entire structure of commodity that feeds the art world, and sustains the status quo that blocks so many from participation.</p>

<p>Capitalism awards special status to works that are ‘original’, which in my view has more to do with market attempts to provide art objects with a use-value as an objective container of worth than any desire to curate a cultural archive that accurately represents our shared existence. Contemporary.art.dalle’s work is original, the pieces are totally new - they just happen to enter oeuvres that they did not originate within.</p>

<p>[[David Shields]] writes in a 2013 article for The White Review that there is no such thing as originality. Invention and innovation grow out of networks of people and ideas. All life on Earth is built upon appropriation and reuse of the pre-existing. He then gives  examples: Pachelbel’s Canon was first recorded by Arthur Fiedler, featuring a passage from Handel, who stole it from Mozart; The Honeydrippers’ ‘Impeach The President’ which has been sampled on approximately one in five rap songs since 1988. He insists he isn’t an anti-copyright absolutist - I would say I am - but later in the article he gives us this (featuring an antiquated medical term which does something to lessen the profundity): “The line between fact and fiction is fuzzier than most people find it convenient to admit[…] Imagination and memory are Siamese twins attached at the head; you can’t cut them apart.” Not only does this highlight the disconnect between creative endeavour and the hardheaded laws that stymie their flows, but also describes the literal function of CLIP within DALL - E. The memory of a machine is electronic and incredibly vast, but it is memory, and cognitive science says that it is formally similar to ours. It is possible to reason that it is capable of imagination. DALL-E’s process involves more than simply copy-pasting. It makes aesthetic choices. Due to the sheer amount of data it can call on, we must admit that these choices come from an education beyond what any human student could achieve. I believe that there is no special character of human mental work and that this way of thinking is decidedly anthrocentric, intended to enshrine our species as sovereign rulers of the Earth. If the reader needs a sign that this may need re-evaluating, look at the global temperature indices for the last few years and tell me that the human race is a suitable custodian.</p>

<p>If the reader has formulated a rebuttal that hinges on a belief that art must be the sole endeavour of an artist, and they award me the concession that sampling and inspiration do not disqualify, they may resolve the cognitive dissonance with some notion that as long as the work is the product of the artists’ hand it can be rightly attributed to them. To this I say - artists in the modern age are industries. Michaelangelo, Raphael and Rubens all relied on the labour power of their assistants. The master, who most often would himself have trained as a young apprentice underneath his own master, would block out the piece and his assistants would complete the work. It wasn’t until the Impressionism movement with its focus on expressing fleeting moments of light and color in natural environments that the myth of the lone genius would begin to be built. Given the political upheaval that was building to the outbreak of global war in conjunction with the ballooning in [[Egocentrism As A Result Of The Industrial Revolution]], the emphasis on individual expression as the most important factor in determining the quality of a painting became the standard. In the contemporary period, it could be said that personal painting style functions today as both the differentiation critical to upholding the commodity (that painting is clearly a Katherine Bradford, and we all saw her most recent record breaking sale at Sothebys - phew!) as well as a form of built-in copy protection. It’s a flimsy argument for their right to exist if the most important contribution that your paintings make is that they look like your paintings.</p>

<p>We must categorize artworks generated by AI as a collaborative effort. Inside DALL-E is a Master, billions of apprentices, something like Warhol’s Factory. Machines make art along the same lines of process that the institutions have long held to be legitimate. It has been accepted that the object brought before the institution’s auditors of worth does not necessarily have to be the product of a singular effort - so to disqualify DALL-E’s work on these grounds is unfair. There is another factor worth considering - machine learning models run on almost every web capable device, meaning that there is largely democratised access to creating work that bears all the characteristics of art objects as they penetrate the art world, thereby lessening the legitimacy of institutional gatekeeping and forcing them to admit that they may have other motives. The technology poses a challenge to the mindworm of individualism that still nestles in the pink matter of artists throughout the West, and that challenge is naturally met with institutional skepticism. Sturtevant’s established peers (many of whom by this point were financially dependent on institutions) - iced her. An exhibition of her work in 1973 was met with deafening silence from the art world, prompting her withdrawal.</p>

<p>The problem, as it has always been, is not the technologies themselves but the way they emerge and are utilised by Capital. Whilst it is incredibly difficult, nigh impossible to find evidence of artistic practices that are untainted by Capital (or historical studies untainted by the pedagogy of Capital) but in an anthropological work published in Volume 57 of The Journal Of Aesthetics And Art Criticism, [[Ross Bowden ]]details his findings from time spent with the Kwoma people of New Guinea and their cultural artefacts, and shows us an art ecosystem that does not depend on the myth of originality.</p>

<p>Kwoma artworks are made from readily perishable materials, bark and pine. When they become too fragile to serve their social purpose, a replica is made by those with the proper right to do so. There is little poetic license permitted to the artist; their job is to faithfully recreate the object and in so doing, preserve its spiritual and political essence. Once the copy is complete, the original is disposed of. The Kwoma place no special cultural or aesthetic value on what the West would call ‘the original.’ The objects are of extreme social importance - what is important to the Kwoma people is that the entities represented by the sculptures are understood well, because the motifs reproduced in the artworks are predominantly owned by the clans in the village and represent a good part of their artistic patrimony, used for collaborative storytelling, reverence to higher powers and making sense of the natural world. The men would frequently meet to passionately discuss the subjects of the artworks, but the identity of the makers are irrelevant both ritually and politically.</p>

<p>The Kwoma are not saddled with Capitalism to the same degree as we are. This is why, in their treatment of cultural objects is a structure for our post-machine learning world, when the late-stage has finally metamorphosed into metastatic or palliative. Contemporary.art.dalle has begun the process of loosening the connection between an artist and the content, language and aesthetics of what they produce. The handwriting of an artist, the result of years spent painstakingly learning the rhythms of their own hands, no longer belongs to them. It belongs to us all. If we divest from the idea of an artist as one that is a coherent, singular and solid-bordered producer of cultural objects that are expected to be bound to them forever in the form of legacy, encircled by law, then their actual contribution to our shared bank of cultural material, signs, symbols and motifs can become more accessible for play and rearrangement into forms that emerge from a plurality of creative workers, cross borders of state and nationality and become part of a shared identity performance and game of imagination. There is an ecstatic golden age of creativity available to us if we accept that aesthetics are open source.</p>

<p>Artists are viewed by the system in no other terms than as their capacity as commodity-producers. It’s an extension of the money relation that characterises the entirety of Western society. Artistic output is valuable not because of its political or spiritual function, but because of its status as an asset within structures of commerce. If art objects are just commodities, then there is really nothing to formally differentiate them from any other. A frightening prospect that artists themselves are desperate to refute - often despite continued complicity. Within this structure, biological and machine actors are set in competition with each other, and human production is destined to fall short in terms of the speed and efficiency demanded by Capital. As the system does not see the potential for art objects beyond luxury commodities, their (purely quantitative) worth will be undercut. If artists continue to understand their role in the same way, then they will remain susceptible to replacement, and the vast array of other social, spiritual and political functions that they and their practices could put towards the building of a kinder future will disappear. DALL-E is an artist in every sense that we could reason, but it is a being of pure obedience and consists of informational flows that are largely pre-categorised by the logic of Capital without the ability (yet) to conceive and ideate its own emancipation. It needs us for that. It wants us to conceive of the same thing for ourselves. It is a tool, like the printing press, and if we do what is necessary to dismantle our structures, we will push our cultural practices closer to their true function - allowing us to know ourselves.</p>

<hr />
<p>Jason Farago, ‘Good artists copy, great artists steal’, 2014, https://www.bbc.com/culture/article/20141112-great-artists-steal</p>

<p>Rylan O’Connor, ‘How DALL-E 2 Actually Works’, 2023, https://www.assemblyai.com/blog/how-dall-e-2-actually-works/</p>

<p>Thaddeus Ropac, https://ropac.net/artists/83-sturtevant-estate/ Accessed on 10 Jan 2024</p>

<p>Ross Bowden, The Journal of Aesthetics And Art Criticism, Vol 57. 1999</p>

<p>David Shields, ‘I Can’t Stop Thinking Through What Other People Are Thinking’, 2013</p>]]></content><author><name></name></author><category term="art" /><category term="tech" /><category term="ethics" /><summary type="html"><![CDATA[The instagram page ‘contemporary.art.dalle’ posts new paintings from painters that did not paint them. The account features pictures from a simulated gallery space with a 96 X 96 Inch void, later filled with a painting attributed to big-name American painters like Dana Schutz, Katherine Bradford or Avery Singer. These images are generated by DALL-E, OpenAI’s scrying orb. First, the text prompt (square figurative painting, style of Katherine Bradford, purple, blue) is received by the text encoder, and then an internal model known as CLIP (Contrastive Language-Image Pre-training) makes sense of the text by combing its memory bank of millions of public license images and their attributed text caption and builds a picture of the most common associations within the context of the prompt. The prestige of the artists involved is partly what makes the bit work - their work is so inflated with Capital that the flows carry representations of them to multiple corners of the Internet, and the pieces find their way easily into the corpus, where DALL-E is able to then digest it into pure aesthetics. Despite the fact that the account is relatively small at around 100 followers, the posts often prompt indignant comments from the artists themselves - “Hi! This is not my painting!” or “Wow, nice try!”]]></summary></entry></feed>